# -*- coding: utf-8 -*-
"""
diyapi_anti_entropy_server.py

Performs weekly or monthly consistency checks on every avatar.
Query each machine for a "database consistency check hash" 
(see below) for the avatar.
Every machine on the network replies with it's consistency check hash for 
that avatar.
If consistency hashes match, done, move on to next avatar.
If consistency hashes don't match, schedule avatar for recheck in an hour.
For any avatar that misses 3 consistency checks in a row, 
do item level comparisons between nodes (see below.)

Avatar's "database consistency hash": 
Generated by querying the DB only on each machine for each avatar. 
A hash is constructed from the sorted keys, 
adding the key, and the timestamp from the value, 
and the md5 from the stored value (if we have data) 
or a marker for a tombstone if we have one of those.

Item level comparisons: Pull all 10 databases. Iterate through them. 
(since they are all sorted, this doesn't require unbounded memory.) 
Ignore keys stored in the last hour, which may still be settling. 
Based on the timestamp values present for each key, 
you should be able to determine the "correct" state. 
I.e. if a tombstone is present, it means any earlier keys should not be there. 
If only some (but not all) shares are there, the remaining shares should be 
reconstructed and added. 
Any other situation would indicate a data integrity error 
that should be resolved.
"""
from collections import deque, namedtuple
import datetime
import logging
import os
import sys
import time
import uuid

import zmq

from diyapi_tools.zeromq_pollster import ZeroMQPollster
from diyapi_tools.xrep_server import XREPServer
from diyapi_tools.pull_server import PULLServer
from diyapi_tools.resilient_client import ResilientClient
from diyapi_tools.deque_dispatcher import DequeDispatcher
from diyapi_tools import time_queue_driven_process

from diyapi_anti_entropy_server.common import max_retry_count, \
        retry_entry_tuple, \
        retry_time
from diyapi_anti_entropy_server.audit_result_database import \
        AuditResultDatabase
from diyapi_anti_entropy_server.avatar_list_requestor import \
        AvatarListRequestor
from diyapi_anti_entropy_server.consistency_check_starter import \
        ConsistencyCheckStarter
from diyapi_anti_entropy_server.retry_manager import \
        RetryManager
from diyapi_anti_entropy_server.state_cleaner import \
        StateCleaner

_node_names = os.environ['SPIDEROAK_MULTI_NODE_NAME_SEQ'].split()
_local_node_name = os.environ["SPIDEROAK_MULTI_NODE_NAME"]
_log_path = u"/var/log/pandora/diyapi_anti_entropy_server_%s.log" % (
    _local_node_name,
)
_client_tag = "anti-entropy-server-%s" % (_local_node_name, )
_database_server_addresses = \
    os.environ["DIYAPI_DATABASE_SERVER_ADDRESSES"].split()
_anti_entropy_server_address = os.environ.get(
    "DIYAPI_ANTI_ENTROPY_SERVER_ADDRESS",
    "tcp://127.0.0.1:8600"
)
_anti_entropy_server_pipeline_address = os.environ.get(
    "DIYAPI_ANTI_ENTROPY_SERVER_PIPELINE_ADDRESS",
    "tcp://127.0.0.1:8650"
)
_request_timeout = 5.0 * 60.0
_error_hash = "*** error ***"

_request_state_tuple = namedtuple("RequestState", [ 
    "xrep_ident",
    "timestamp",
    "timeout",
    "avatar_id",
    "retry_count",
    "replies",
    "row_id",
])

def _start_consistency_check(state, avatar_id, row_id=None, retry_count=0):
    log = logging.getLogger("_start_consistency_check")
    log.info("start consistency check on %s" % (avatar_id, ))

    request_id = uuid.uuid1().hex
    timestamp = datetime.datetime.now()

    database = AuditResultDatabase()
    if row_id is None:
        row_id = database.start_audit(avatar_id, timestamp)
    else:
        database.restart_audit(row_id, timestamp)
    database.close()

    state["active-requests"][request_id] = _request_state_tuple(
        xrep_ident=None,
        timestamp=timestamp,
        timeout=time.time()+_request_timeout,
        avatar_id=avatar_id,
        retry_count=retry_count,
        replies=dict(), 
        row_id=row_id
    )

    request = {
        "message-type"  : "consistency-check",
        "request-id"    : request_id,
        "avatar-id"     : avatar_id,
        "timestamp"     : time.mktime(timestamp.timetuple()),
    }
    for database_client in state["database-clients"]:
        database_client.queue_message_for_send(request)

def _handle_anti_entropy_audit_request(state, message, _data):
    """handle a requst to audit a specific avatar, not some random one"""
    log = logging.getLogger("_handle_anti_entropy_audit_request")
    log.info("request for audit on %s" % (message["avatar-id"], )) 

    timestamp = datetime.datetime.now()

    database = AuditResultDatabase()
    row_id = database.start_audit(message["avatar-id"], timestamp)
    database.close()

    state["active-requests"][message["request-id"]] = _request_state_tuple(
        xrep_ident=message["xrep-ident"],
        timestamp=timestamp,
        timeout=time.time()+_request_timeout,
        avatar_id=message["avatar-id"],
        retry_count=max_retry_count,
        replies=dict(), 
        row_id=row_id
    )

    request = {
        "message-type"  : "consistency-check",
        "request-id"    : message["request-id"],
        "avatar-id"     : message["avatar-id"],
        "timestamp"     : time.mktime(timestamp.timetuple()),
    }
    for database_client in state["database-clients"]:
        database_client.queue_message_for_send(request)

def _handle_database_avatar_list_reply(state, message, _data):
    log = logging.getLogger("_handle_database_avatar_list_reply")

    state["avatar-ids"] = set(message["avatar-id-list"])
    log.info("found %s avatar ids" % (len(state["avatar-ids"]), ))

def _handle_database_consistency_check_reply(state, message, _data):
    log = logging.getLogger("_handle_database_consistency_check_reply")

    request_id = message["request-id"]

    try:
        request_state = state["active-requests"][request_id]
    except KeyError:
        log.warn("Unknown request_id %s from %s" % (
            message["request-id"], message["node-name"]
        ))
        return

    if message["result"] != "success":
        log.error("%s (%s) %s from %s %s" % (
            request_state.avatar_id, 
            message["result"],
            message["error-message"],
            message["node-name"],
            message["request-id"]
        ))
        hash_value = _error_hash
    else:
        hash_value = message["md5-digest"]

    # if this audit was started by an anti-entropy-audit-request message,
    # we want to send a reply
    if request_state.xrep_ident is not None:
        reply = {
            "message-type"  : "anti-entropy-audit-reply",
            "xrep-ident"    : request_state.xrep_ident,
            "request-id"    : request_id,
            "result"        : None,
            "error-message" : None,
        }
    else:
        reply = None
        
    if message["node-name"] in request_state.replies:
        error_message = "duplicate reply from %s %s %s" % (
            message["node-name"],
            request_state.avatar_id, 
            request_id
        )
        log.error(error_message)
        if reply is not None:
            reply["result"] = "error"
            reply["error-message"] = error_message
            state["xrep-server"].queue_message_for_send(reply)
        return

    request_state.replies[message["node-name"]] = hash_value

    # not done yet, wait for more replies
    if len(request_state.replies) < len(state["database-clients"]):
        return

    # at this point we should have a reply from every node, so
    # we don't want to preserve state anymore
    del state["active-requests"][request_id]
    database = AuditResultDatabase()
    timestamp = datetime.datetime.now()
    
    hash_list = list(set(request_state.replies.values()))
    
    # ok - all have the same hash
    if len(hash_list) == 1 and hash_list[0] != _error_hash:
        log.info("avatar %s compares ok" % (request_state.avatar_id, ))
        database.successful_audit(request_state.row_id, timestamp)
        if reply is not None:
            reply["result"] = "success"
            state["xrep-server"].queue_message_for_send(reply)
        return

    # we have error(s), but the non-errors compare ok
    if len(hash_list) == 2 and _error_hash in hash_list:
        error_count = 0
        for value in request_state.replies.values():
            if value == _error_hash:
                error_count += 1

        # if we come from anti-entropy-audit-request, don't retry
        if reply is not None:
            database.audit_error(request_state.row_id, timestamp)
            database.close()
            error_message = "There were %s error hashes" % (error_count, )
            log.error(error_message)
            reply["result"] = "error"
            reply["error-message"] = error_message
            state["xrep-server"].queue_message_for_send(reply)
            return
        
        if request_state.retry_count >= max_retry_count:
            log.error("avatar %s %s errors, too many retries" % (
                request_state.avatar_id, 
                error_count
            ))
            database.audit_error(request_state.row_id, timestamp)
            # TODO: needto do something here
        else:
            log.warn("avatar %s %s errors, will retry" % (
                request_state.avatar_id, 
                error_count
            ))
            state["retry-list"].append(
                retry_entry_tuple(
                    retry_time=retry_time(), 
                    avatar_id=request_state.avatar_id,
                    row_id=request_state.row_id,
                    retry_count=request_state.retry_count, 
                )
            )
            database.wait_for_retry(request_state.row_id)
        database.close()
        return

    # if we make it here, we have some form of mismatch, possibly mixed with
    # errors
    error_message = "avatar %s hash mismatch" % (request_state.avatar_id, )
    log.error(error_message)
    for node_name, value in request_state.replies.items():
        log.error("    node %s value %s" % (node_name, value, ))

    # if we come from anti-entropy-audit-request, don't retry
    if reply is not None:
        database.audit_error(request_state.row_id, timestamp)
        database.close()
        reply["result"] = "audit-error"
        reply["error-message"] = error_message
        state["xrep-server"].queue_message_for_send(reply)
        return

    if request_state.retry_count >= max_retry_count:
        log.error("%s too many retries" % (request_state.avatar_id, ))
        database.audit_error(request_state.row_id, timestamp)
        # TODO: need to do something here
    else:
        state["retry-list"].append(
            retry_entry_tuple(
                retry_time=retry_time(), 
                avatar_id=request_state.avatar_id,
                row_id=request_state.row_id,
                retry_count=request_state.retry_count, 
            )
        )
        database.wait_for_retry(request_state.row_id)

    database.close()

_dispatch_table = {
    "anti-entropy-audit-request" : _handle_anti_entropy_audit_request,
    "avatar-list-reply"          : _handle_database_avatar_list_reply,
    "consistency-check-reply"    :  _handle_database_consistency_check_reply,
}

def _create_state():
    return {
        "zmq-context"               : zmq.Context(),
        "pollster"                  : ZeroMQPollster(),
        "xrep-server"               : None,
        "pull-server"               : None,
        "database-clients"          : None,
        "avatar-list-requestor"     : None,
        "consistency-check-starter" : None,
        "retry_manager"             : None,
        "state-cleaner"             : None,
        "receive-queue"             : deque(),
        "queue-dispatcher"          : None,
        "active-requests"           : dict(),
        "retry-list"                : list(),
        "avatar-ids"                : set(),
    }

def _setup(_halt_event, state):
    log = logging.getLogger("_setup")

    log.info("binding xrep-server to %s" % (_anti_entropy_server_address, ))
    state["xrep-server"] = XREPServer(
        state["zmq-context"],
        _anti_entropy_server_address,
        state["receive-queue"]
    )
    state["xrep-server"].register(state["pollster"])

    log.info("binding pull-server to %s" % (
        _anti_entropy_server_pipeline_address, 
    ))
    state["pull-server"] = PULLServer(
        state["zmq-context"],
        _anti_entropy_server_pipeline_address,
        state["receive-queue"]
    )
    state["pull-server"].register(state["pollster"])

    state["database-clients"] = list()
    for node_name, database_server_address in zip(
        _node_names, _database_server_addresses
    ):
        resilient_client = ResilientClient(
                state["zmq-context"],
                state["pollster"],
                node_name,
                database_server_address,
                _client_tag,
                _anti_entropy_server_pipeline_address
            )
        state["database-clients"].append(resilient_client)

    state["queue-dispatcher"] = DequeDispatcher(
        state,
        state["receive-queue"],
        _dispatch_table
    )

    state["avatar-list-requestor"] = AvatarListRequestor(state)
    state["consistency-check-starter"] = ConsistencyCheckStarter(
        state, _start_consistency_check
    )
    state["retry-manager"] = RetryManager(
        state, _start_consistency_check
    )
    state["state-cleaner"] = StateCleaner(state)

    # hand the pollster and the queue-dispatcher to the time-queue 
    # start the avatar list requestor right away
    # start the consistency check starter a little later, when
    # we presumably have some avatar ids
    return [
        (state["pollster"].run, time.time(), ), 
        (state["queue-dispatcher"].run, time.time(), ), 
        (state["avatar-list-requestor"].run, time.time(), ), 
        (state["consistency-check-starter"].run, time.time()+60.0, ), 
        (state["retry-manager"].run, state["retry-manager"].next_run(), ), 
        (state["state-cleaner"].run, state["state-cleaner"].next_run(), ), 
    ] 

def _tear_down(_state):
    log = logging.getLogger("_tear_down")

    log.debug("stopping xrep server")
    state["xrep-server"].close()

    log.debug("stopping database clients")
    state["pull-server"].close()
    for database_client in state["database-clients"]:
        database_client.close()

    state["zmq-context"].term()

    log.debug("teardown complete")

if __name__ == "__main__":
    state = _create_state()
    sys.exit(
        time_queue_driven_process.main(
            _log_path,
            state,
            pre_loop_actions=[_setup, ],
            post_loop_actions=[_tear_down, ]
        )
    )

