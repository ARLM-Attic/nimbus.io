# -*- coding: utf-8 -*-
"""
diyapi_anti_entropy_server.py

Performs weekly or monthly consistency checks on every avatar.
Query each machine for a "database consistency check hash" 
(see below) for the avatar.
Every machine on the network replies with it's consistency check hash for 
that avatar.
If consistency hashes match, done, move on to next avatar.
If consistency hashes don't match, schedule avatar for recheck in an hour.
For any avatar that misses 3 consistency checks in a row, 
do item level comparisons between nodes (see below.)

Avatar's "database consistency hash": 
Generated by querying the DB only on each machine for each avatar. 
A hash is constructed from the sorted keys, 
adding the key, and the timestamp from the value, 
and the md5 from the stored value (if we have data) 
or a marker for a tombstone if we have one of those.

Item level comparisons: Pull all 10 databases. Iterate through them. 
(since they are all sorted, this doesn't require unbounded memory.) 
Ignore keys stored in the last hour, which may still be settling. 
Based on the timestamp values present for each key, 
you should be able to determine the "correct" state. 
I.e. if a tombstone is present, it means any earlier keys should not be there. 
If only some (but not all) shares are there, the remaining shares should be 
reconstructed and added. 
Any other situation would indicate a data integrity error 
that should be resolved.
"""
from base64 import b64encode, b64decode
from collections import deque, namedtuple, defaultdict
import hashlib
import logging
import os
import cPickle as pickle
import random
import sys
import time

import zmq

from diyapi_tools.zeromq_pollster import ZeroMQPollster
from diyapi_tools.resilient_server import ResilientServer
from diyapi_tools.pull_server import PULLServer
from diyapi_tools.resilient_client import ResilientClient
from diyapi_tools.deque_dispatcher import DequeDispatcher
from diyapi_tools import time_queue_driven_process
from diyapi_tools.data_definitions import create_timestamp, \
        parse_timestamp_repr
from diyapi_tools.database_connection import get_central_connection, \
        get_node_local_connection

from diyapi_web_server.central_database_util import get_cluster_row, \
        get_collections_for_avatar

from diyapi_anti_entropy_server.common import max_retry_count, \
        retry_entry_tuple, \
        retry_time
from diyapi_anti_entropy_server.audit_result_database import \
        AuditResultDatabase
from diyapi_anti_entropy_server.avatar_list_requestor import \
        AvatarListRequestor
from diyapi_anti_entropy_server.consistency_check_starter import \
        ConsistencyCheckStarter
from diyapi_anti_entropy_server.retry_manager import \
        RetryManager
from diyapi_anti_entropy_server.state_cleaner import \
        StateCleaner

_node_names = os.environ['SPIDEROAK_MULTI_NODE_NAME_SEQ'].split()
_local_node_name = os.environ["SPIDEROAK_MULTI_NODE_NAME"]
_log_path = u"/var/log/pandora/diyapi_anti_entropy_server_%s.log" % (
    _local_node_name,
)
_client_tag = "anti-entropy-server-%s" % (_local_node_name, )
_anti_entropy_server_addresses = \
    os.environ["DIYAPI_ANTI_ENTROPY_SERVER_ADDRESSES"].split()
_anti_entropy_server_pipeline_address = os.environ.get(
    "DIYAPI_ANTI_ENTROPY_SERVER_PIPELINE_ADDRESS",
    "tcp://127.0.0.1:8650"
)
_request_timeout = 5.0 * 60.0
_error_reply = "*** error ***"

_request_state_tuple = namedtuple("RequestState", [ 
    "client_tag",
    "timestamp",
    "timeout",
    "retry_count",
    "replies",
    "row_id",
    "collections_dict",
])

def _start_consistency_check(state, avatar_id, row_id=None, retry_count=0):
    log = logging.getLogger("_start_consistency_check")

    timestamp = create_timestamp()
    state_key = (avatar_id, timestamp, )

    collections_for_avatar = get_collections_for_avatar(
        state["central-database-connection"], 
        state["cluster-row"].id, 
        avatar_id
    )
    collections_dict = dict(collections_for_avatar)

    log.info("start consistency check on %s %s connections" % (
        avatar_id, len(collections_dict),
    ))

    database = AuditResultDatabase(state["central-database-connection"])
    if row_id is None:
        row_id = database.start_audit(avatar_id, timestamp)
    else:
        database.restart_audit(row_id, timestamp)
    database.close()

    state["active-requests"][state_key] = _request_state_tuple(
        client_tag=None,
        timestamp=timestamp,
        timeout=time.time()+_request_timeout,
        retry_count=retry_count,
        replies=dict(), 
        row_id=row_id,
        collections_dict=collections_dict
    )

    request = {
        "message-type"  : "consistency-check",
        "avatar-id"     : avatar_id,
        "timestamp-repr": repr(timestamp),
    }
    data = pickle.dumps(collections_dict)
    for anti_entropy_client in state["anti-entropy-clients"]:
        anti_entropy_client.queue_message_for_send(request, data)

def _handle_anti_entropy_audit_request(state, message, _data):
    """handle a requst to audit a specific avatar, not some random one"""
    log = logging.getLogger("_handle_anti_entropy_audit_request")

    timestamp = create_timestamp()
    state_key = (message["avatar-id"], timestamp, )

    collections_for_avatar = get_collections_for_avatar(
        state["central-database-connection"], 
        state["cluster-row"].id, 
        message["avatar-id"]
    )
    collections_dict = dict(collections_for_avatar)
    log.info("request for audit on %s %s collectons" % (
        message["avatar-id"], len(collections_dict), 
    )) 

    database = AuditResultDatabase(state["central-database-connection"])
    row_id = database.start_audit(message["avatar-id"], timestamp)
    database.close()

    state["active-requests"][state_key] = _request_state_tuple(
        client_tag=message["client-tag"],
        timestamp=timestamp,
        timeout=time.time()+_request_timeout,
        retry_count=max_retry_count,
        replies=dict(), 
        row_id=row_id,
        collections_dict=collections_dict
    )

    request = {
        "message-type"  : "consistency-check",
        "avatar-id"     : message["avatar-id"],
        "timestamp-repr": repr(timestamp),
    }
    data = pickle.dumps(collections_dict)
    for anti_entropy_client in state["anti-entropy-clients"]:
        anti_entropy_client.queue_message_for_send(request, data)

def _handle_database_avatar_list_reply(state, message, _data):
    log = logging.getLogger("_handle_database_avatar_list_reply")

    state["avatar-ids"] = set(message["avatar-id-list"])
    log.info("found %s avatar ids" % (len(state["avatar-ids"]), ))

def _handle_consistency_check(state, message, data):
    log = logging.getLogger("_handle_consistency_check")

    reply = {
        "message-type"      : "consistency-check-reply",
        "client-tag"        : message["client-tag"],
        "node-name"         : _local_node_name,
        "avatar-id"         : message["avatar-id"],
        "timestamp-repr"    : message["timestamp-repr"],
        "result"            : None,
        "error-message"     : None
    }

    try:
        collection_dict = pickle.loads(data)
    except Exception, instance:
        error_message = "unable to unpickle collection dict %s" % (instance, )
        log.error("%s %s" % (message["avatar-id"], error_message, ))
        reply["result"] = "invalid_collection_list"
        reply["error-message"] = error_message
        state["resilient-server"].send_reply(reply, None)
        return

    result_dict = dict()
    for collection_id in collection_dict.keys():
        data_generator = state["local-database-connection"].generate_all_rows(
            """
            select key, timestamp, file_hash 
            from diy.segment where collection_id = %s
            order by key
            """.strip(),
            [collection_id, ]
        )

        count = 0
        md5 = hashlib.md5()
        prev_key = None
        for key, timestamp, file_hash in data_generator:
            count += 1
            if key != prev_key:
                md5.update(key)
                prev_key = key
            md5.update(repr(timestamp))
            md5.update(str(file_hash))

        log.info("found %s rows for avatar %s %s collection (%s) %r" % (
            count, 
            message["avatar-id"],             
            message["timestamp-repr"],
            collection_id,
            collection_dict[collection_id],
        ))

        result_dict[collection_id] = {
            "count"                 : count,
            "encoded-md5-digest"    : b64encode(md5.digest())
        }

    reply["result"] = "success"
    state["resilient-server"].send_reply(reply, pickle.dumps(result_dict))

def _handle_consistency_check_reply(state, message, data):
    log = logging.getLogger("_handle_consistency_check_reply")
    
    timestamp = parse_timestamp_repr(message["timestamp-repr"])
    state_key = (message["avatar-id"], timestamp, )

    try:
        request_state = state["active-requests"][state_key]
    except KeyError:
        log.warn("Unknown state_key %s from %s" % (
            state_key, message["node-name"]
        ))
        return

    if message["node-name"] in request_state.replies:
        error_message = "duplicate reply from %s %s" % (
            message["node-name"],
            state_key, 
        )
        log.error(error_message)
        return

    if message["result"] != "success":
        log.error("%s (%s) %s from %s" % (
            state_key, 
            message["result"],
            message["error-message"],
            message["node-name"],
        ))
        reply_value = _error_reply
    else:
        try:
            reply_value = pickle.loads(data)
        except Exception, instance:
            log.error("%s unable to unpickle reply from %s %s" % (
                message["avatar-id"], message["node-name"], instance
            ))
            reply_value = _error_reply

    request_state.replies[message["node-name"]] = reply_value

    # not done yet, wait for more replies
    if len(request_state.replies) < len(state["anti-entropy-clients"]):
        return

    # at this point we should have a reply from every node, so
    # we don't want to preserve state anymore
    del state["active-requests"][state_key]
    database = AuditResultDatabase(state["central-database-connection"])
    timestamp = create_timestamp()
    
    reply_error_count = 0
    # push the results into a set to see how many unique entries there are
    collection_sets = defaultdict(set)

    for node_name in request_state.replies.keys():
        node_reply = request_state.replies[node_name]
        if node_reply == _error_reply:
            reply_error_count += 1
            continue

        for collection_id in request_state.collection_dict.keys():
            collection_sets[collection_id].add(
                node_reply[collection_id]["encoded-md5-digest"]
            )


    # if this audit was started by an anti-entropy-audit-request message,
    # we want to send a reply
    if request_state.client_tag is not None:
        reply = {
            "message-type"  : "anti-entropy-audit-reply",
            "client-tag"    : request_state.client_tag,
            "avatar-id"     : message["avatar-id"],
            "result"        : None,
            "error-message" : None,
        }
    else:
        reply = None

    collection_error_count = 0
    for collection_id in request_state.collection_dict.keys():
        if len(collection_sets[collection_id]) != 1:
            log.error("collection set of %s for (%s) %r" % (
                len(collection_sets[collection_id]), 
                collection_id,
                request_state.collection_dict[collection_id]
            ))
            collection_error_count += 1
        
    # ok = no errors and all nodes have the same hash for every collection
    if reply_error_count == 0 and collection_error_count == 0:
        log.info("avatar %s compares ok" % (message["avatar-id"], ))
        database.successful_audit(request_state.row_id, timestamp)
        if reply is not None:
            reply["result"] = "success"
            state["resilient-server"].send_reply(reply)
        return

    # we have error(s), but the non-errors compare ok
    if reply_error_count > 0 and collection_error_count == 0:

        # if we come from anti-entropy-audit-request, don't retry
        if reply is not None:
            database.audit_error(request_state.row_id, timestamp)
            database.close()
            error_message = "There were error replies from %s nodes" % (
                reply_error_count, 
            )
            log.error(error_message)
            reply["result"] = "error"
            reply["error-message"] = error_message
            state["resilient-server"].send_reply(reply)
            return
        
        if request_state.retry_count >= max_retry_count:
            log.error("avatar %s %s errors, too many retries" % (
                message["avatar-id"], 
                reply_error_count
            ))
            database.audit_error(request_state.row_id, timestamp)
            # TODO: needto do something here
        else:
            log.warn("%s Error replies from %s nodes, will retry" % (
                message["avatar-id"], 
                reply_error_count
            ))
            state["retry-list"].append(
                retry_entry_tuple(
                    retry_time=retry_time(), 
                    avatar_id=message["avatar-id"],
                    row_id=request_state.row_id,
                    retry_count=request_state.retry_count, 
                )
            )
            database.wait_for_retry(request_state.row_id)
        database.close()
        return

    # if we make it here, we have some form of mismatch, possibly mixed with
    # errors
    error_message = "%s errors from %s nodes; mismatches on %s collections" % (
        message["avatar-id"], reply_error_count, collection_error_count
    )
    log.error(error_message)

    # if we come from anti-entropy-audit-request, don't retry
    if reply is not None:
        database.audit_error(request_state.row_id, timestamp)
        database.close()
        reply["result"] = "audit-error"
        reply["error-message"] = error_message
        state["resilient-server"].send_reply(reply)
        return

    if request_state.retry_count >= max_retry_count:
        log.error("%s too many retries" % (message["avatar-id"], ))
        database.audit_error(request_state.row_id, timestamp)
        # TODO: need to do something here
    else:
        state["retry-list"].append(
            retry_entry_tuple(
                retry_time=retry_time(), 
                avatar_id=message["avatar-id"],
                row_id=request_state.row_id,
                retry_count=request_state.retry_count, 
            )
        )
        database.wait_for_retry(request_state.row_id)

    database.close()

_dispatch_table = {
    "anti-entropy-audit-request"    :  _handle_anti_entropy_audit_request,
    "consistency-check"             :  _handle_consistency_check,
    "consistency-check-reply"       :  _handle_consistency_check_reply,
}

def _create_state():
    return {
        "central-database-connection": None,
        "local-database-connection" : None,
        "zmq-context"               : zmq.Context(),
        "pollster"                  : ZeroMQPollster(),
        "resilient-server"          : None,
        "pull-server"               : None,
        "anti-entropy-clients"      : None,
        "avatar-list-requestor"     : None,
        "consistency-check-starter" : None,
        "retry_manager"             : None,
        "state-cleaner"             : None,
        "receive-queue"             : deque(),
        "queue-dispatcher"          : None,
        "active-requests"           : dict(),
        "retry-list"                : list(),
        "avatar-ids"                : set(),
        "cluster-row"               : None,
    }

def _setup(_halt_event, state):
    log = logging.getLogger("_setup")
    status_checkers = list()

    state["central-database-connection"] = get_central_connection()
    state["local-database-connection"] = get_node_local_connection()

    state["cluster-row"] = get_cluster_row(
        state["central-database-connection"] 
    )

    local_anti_entropy_server_address = None
    for node_name, address in zip(_node_names, _anti_entropy_server_addresses):
        if node_name == _local_node_name:
            local_anti_entropy_server_address = address
            break
    assert local_anti_entropy_server_address is not None

    log.info("binding resilient-server to %s" % (
        local_anti_entropy_server_address, 
    ))
    state["resilient-server"] = ResilientServer(
        state["zmq-context"],
        local_anti_entropy_server_address,
        state["receive-queue"]
    )
    state["resilient-server"].register(state["pollster"])

    log.info("binding pull-server to %s" % (
        _anti_entropy_server_pipeline_address, 
    ))
    state["pull-server"] = PULLServer(
        state["zmq-context"],
        _anti_entropy_server_pipeline_address,
        state["receive-queue"]
    )
    state["pull-server"].register(state["pollster"])

    state["anti-entropy-clients"] = list()
    for node_name, anti_entropy_server_address in zip(
        _node_names, _anti_entropy_server_addresses
    ):
        resilient_client = ResilientClient(
                state["zmq-context"],
                state["pollster"],
                node_name,
                anti_entropy_server_address,
                _client_tag,
                _anti_entropy_server_pipeline_address
            )
        state["anti-entropy-clients"].append(resilient_client)
        status_checkers.append(
            (resilient_client.run, time.time() + random.random() * 60.0, )
        )        

    state["queue-dispatcher"] = DequeDispatcher(
        state,
        state["receive-queue"],
        _dispatch_table
    )

    state["avatar-list-requestor"] = AvatarListRequestor(state)
    state["consistency-check-starter"] = ConsistencyCheckStarter(
        state, _start_consistency_check
    )
    state["retry-manager"] = RetryManager(
        state, _start_consistency_check
    )
    state["state-cleaner"] = StateCleaner(state)

    # start the avatar list requestor right away
    # start the consistency check starter a little later, when
    # we presumably have some avatar ids
    timer_driven_callbacks = [
        (state["pollster"].run, time.time(), ), 
        (state["queue-dispatcher"].run, time.time(), ), 
        (state["avatar-list-requestor"].run, time.time(), ), 
        (state["consistency-check-starter"].run, time.time()+60.0, ), 
        (state["retry-manager"].run, state["retry-manager"].next_run(), ), 
        (state["state-cleaner"].run, state["state-cleaner"].next_run(), ), 
    ] 
    timer_driven_callbacks.extend(status_checkers)
    return timer_driven_callbacks

def _tear_down(_state):
    log = logging.getLogger("_tear_down")

    log.debug("stopping xrep server")
    state["resilient-server"].close()

    log.debug("stopping anti entropy clients")
    state["pull-server"].close()
    for anti_entropy_client in state["anti-entropy-clients"]:
        anti_entropy_client.close()

    state["zmq-context"].term()
    state["local-database-connection"].close()

    log.debug("teardown complete")

if __name__ == "__main__":
    state = _create_state()
    sys.exit(
        time_queue_driven_process.main(
            _log_path,
            state,
            pre_loop_actions=[_setup, ],
            post_loop_actions=[_tear_down, ]
        )
    )

